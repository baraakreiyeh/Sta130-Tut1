{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "a882d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "42457219",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "8a747c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "635122a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "a604a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "4105b7f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows, columns = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "f1c6f399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 391 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset contains {rows} rows and {columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3e9278ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for numeric columns:\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics for numeric columns:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0fb7c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "62562bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for the 'personality' column:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValue counts for the 'personality' column:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "0a00f25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['personality'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a24b1318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.\n",
    "\n",
    "# The dfshape function represents all rows and columuns even no matter if they are numeric or non numeric.\n",
    "# df.describe only analyzis the numeric columns,\n",
    "# thus it left out the non numeric ones leading to the miss match of the size of the dataset vs the size reported\n",
    "\n",
    "# The dfshape function represents all the observations of all data, including the ones missing values\n",
    "# dfdescribe on the other hand only represents the non missing values,\n",
    "# Thus it leads to the miss match of dfshape data vs the dfdescribe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "56f6188a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.\n",
    "\n",
    "# An attribute is a way to give an attribute or a characteristic to an object while performing object oriented programming.\n",
    "# This is used to better describe data or an object for you intended purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "7488e7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.\n",
    "\n",
    "# A method is usally a function that is apart of a class and its attributes.\n",
    "# It performs an action that requires an argument to be passed thus requiring the arguemnt to be placed between the brackets ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "df358406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6. \n",
    "\n",
    "# Count: How many data points are present.\n",
    "# Mean: The average of the data.\n",
    "# Standard Deviation: The spread of data around the mean.\n",
    "# Min: The smallest data point.\n",
    "# 25% (Q1): The value below which 25% of the data lies (lower quartile).\n",
    "# 50% (Median): The middle value of the data.\n",
    "# 75% (Q3): The value below which 75% of the data lies (upper quartile).\n",
    "# Max: The largest data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "5884dac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7.1 You would not want to use deldf['col'] because it will delete the entire column, so if there is a column where some values\n",
    "# are missing data but not all, you would not want to delet the whol column,\n",
    "\n",
    "# Thus you would use dfdropna which ensure to only get rid of or \"drop\" the ones that are empty, thus if some areas have data\n",
    "# and some dont, you can filter out the empty ones and keep all the data\n",
    "\n",
    "# an example would be if you were conduction a survery and there was a certain question line that half of the people skipped or\n",
    "# chose not to answer, you would use dropna to get rid of all the empty data to get all filtered responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "424b720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 vice versa if you wanted to get rid of a whole column and not just the empty data, you would use deldf instead of dropna\n",
    "\n",
    "# example if you wanted to delete a certain property that shows for all books on amazon, ex. size, you could just delete all the\n",
    "# data instead of doing dropna and getting rid of only the books with no size data given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "1910f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 you should use  deldf first before dfdropna in certain scneriows where you dont wana end up getting rid of too much data.\n",
    "# you can use deldf to delete the columns with high amounts of missing data and then run dfdropna to filter out through the rest\n",
    "# of the data and pick up the smaller amounts of missing data left. This will ensure that you dont get rid of too much data to the\n",
    "# point where you might not have enough to conduct your research/analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "19502e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values by column:\n",
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values by column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "c341ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'song' in df.columns:\n",
    "    del df['song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "96c470c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after removing 'style_2':\n",
      "row_n          0\n",
      "id             1\n",
      "name           0\n",
      "gender         0\n",
      "species        0\n",
      "birthday       0\n",
      "personality    0\n",
      "phrase         0\n",
      "full_id        0\n",
      "url            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values after removing 'style_2':\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "144e01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "77ed9351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape before cleaning: (391, 10)\n",
      "Shape after cleaning: (390, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nShape before cleaning:\", df.shape)\n",
    "print(\"Shape after cleaning:\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "411879f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after dropping rows with missing data:\n",
      "row_n          0\n",
      "id             0\n",
      "name           0\n",
      "gender         0\n",
      "species        0\n",
      "birthday       0\n",
      "personality    0\n",
      "phrase         0\n",
      "full_id        0\n",
      "url            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values after dropping rows with missing data:\")\n",
    "print(df_cleaned.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "b8923558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since i printed out all my data and figured out where the sections that had missing data are, I removed the coloumn named \"song\"\n",
    "# because it had 11/12 of the missing data and then I did dropna so I can remove the final missing data piece in \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "7924f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  link to my 1-7 questions chatbot logs https://chatgpt.com/share/66e64b71-82c8-8000-a283-19a310ba70dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "126f3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. **Initial Dataset Exploration**:\n",
    "#    - You started by loading a dataset from a URL using pandas (`villagers.csv` from the TidyTuesday project).\n",
    "#    - The dataset had missing values, and you explored these using `df.isna().sum()`.\n",
    "#    - You asked for assistance on how to determine the number of rows and columns in the dataset using `df.shape` and to print out those values. We also discussed the differences between \"observations\" (rows) and \"variables\" (columns).\n",
    "\n",
    "# 2. **Exploring Data Summaries**:\n",
    "#    - You learned how to provide simple summaries for each column using `df.describe()` and explored column-specific summaries using `df['column'].value_counts()` for non-numeric columns. \n",
    "#    - We noted the difference between numeric and non-numeric variables in terms of how `df.describe()` and `value_counts()` behave.\n",
    "\n",
    "# 3. **Discrepancies Between Dataset Size and df.describe()**:\n",
    "#    - We discussed how `df.shape` gives the full dataset size, while `df.describe()` only summarizes numeric columns and excludes non-numeric variables.\n",
    "#    - The “count” column in `df.describe()` reflects how many non-missing values each numeric column has, and missing data in numeric columns can result in lower counts compared to the total number of rows.\n",
    "\n",
    "# 4. **Attributes vs. Methods**:\n",
    "#    - We explored the difference between an attribute like `df.shape` (which doesn't require parentheses) and a method like `df.describe()` (which is a function that requires parentheses). The analogy between functions in programming and functions in mathematics was briefly touched upon.\n",
    "\n",
    "# 5. **Definitions of Summary Statistics**:\n",
    "#    - We defined each of the summary statistics provided by `df.describe()` in a simplified one-sentence format: `count`, `mean`, `std`, `min`, `25%`, `50%`, `75%`, and `max`.\n",
    "\n",
    "# 6. **Handling Missing Data**:\n",
    "#    - We explored different ways to handle missing data:\n",
    "#      - **`df.dropna()`** removes rows with missing values.\n",
    "#      - **`del df['col']`** removes a column entirely, which can be preferred when a column has too many missing values.\n",
    "#    - We discussed use cases for both methods, such as when you would prefer to drop rows versus when you might want to remove columns entirely.\n",
    "#    - We also explained why applying `del df['col']` before `df.dropna()` can be important when cleaning up a dataset.\n",
    "\n",
    "# 7. **Practical Example of Handling Missing Data**:\n",
    "#    - You wanted to apply a practical example to your specific dataset. We demonstrated how to:\n",
    "#      - Identify columns with a high percentage of missing values (such as `style_2` in your dataset).\n",
    "#      - Remove columns with excessive missing values (using `del df['style_2']`).\n",
    "#      - Remove rows with any remaining missing values (using `df.dropna()`).\n",
    "#    - We provided a \"before and after\" report, showing how the dataset changes after cleaning and the reasoning behind each step.\n",
    "\n",
    "# 8. **Summary of the Entire Process**:\n",
    "#    - The approach involved inspecting missing values, deciding which columns to remove, and then dropping rows with any missing values. This helps balance the loss of data while ensuring high-quality, complete data for analysis.\n",
    "\n",
    "# The conversation provided you with a structured workflow for cleaning and summarizing your dataset, addressing both missing data and key statistical concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "d749b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "1e456208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
       "       'alive', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "d567afee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique     top freq\n",
       "survived                          \n",
       "0          549      2    male  468\n",
       "1          342      2  female  233"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.groupby(\"survived\")[\"sex\"].describe()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "155defc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.2 the function groupby groups by the \"survived\" column and then describes them by thier sex, so it shows that the 549 people\n",
    "# who died were a majority male and shows the frequency of how many were male, same for the the people who survived it shows the\n",
    "# the top was female and the fequency of females in the data was 233 out of the 342 who survived.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "4e2c7072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "9e352704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2 It results in something different because dfdescribe will describe the entire data set with all its columns, on there hand,\n",
    "# dfgroupby calcualtes the data and statictis by certains columns at a time and not all at the same time. The funciton is good if\n",
    "# you want to focus on one group of data at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "760d5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3 Chatbots are 100% better at fixing the erros then using google for many reasons. Firstly, the chatbot has context to\n",
    "# everything. If for example there was a error on line 200 of my code, the error could be because of a previous line like line 130\n",
    "# , goggle might not be able to know this beacuse it doesnt know my previous code. Secondaly, chatgpt can google search for you if\n",
    "# you ask it, it will read multiple websites in an instant and repeat to you the answer that was found online, so it can do a google\n",
    "# search better then you. Lastly, chatbot is better to be organized as it shows your entire histroy of promps on one website, it\n",
    "# gives you the the answer whichever way you want it, code, paragraph reasoning, etc. In an organized manner right after another,\n",
    "# Goggle will have you clicking different websites, openinig links, scouring the whole website, skipping over ads, just to find\n",
    "# for example the an explination or a reasoning paragraph and then youu have to find a whole nother website to try and get the\n",
    "# code for it etc. Chatbots are the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "ae2febd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for question 8 from chatbot,\n",
    "\n",
    "# Exploring Titanic Dataset & Basic Troubleshooting with a ChatBot:\n",
    "\n",
    "# You wanted guidance on using a ChatBot to troubleshoot issues while analyzing the Titanic dataset from Seaborn (https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv).\n",
    "# You started by asking about basic summary analysis with code examples using df.groupby(\"col1\")[\"col2\"].describe(). I explained how this method groups data by col1 and provides statistical descriptions (like count, mean, std, etc.) for col2.\n",
    "# df.describe() and Handling Missing Values:\n",
    "\n",
    "# You asked about the differences between df.describe() and df.groupby(\"col1\")[\"col2\"].describe() in terms of handling missing values.\n",
    "# I explained that df.describe() provides overall summary statistics for the DataFrame, while df.groupby() groups data by a specified column and calculates the statistics within those groups. Missing values affect these counts differently depending on how they are handled within the methods.\n",
    "# Survival Status in Titanic Dataset (survived column):\n",
    "\n",
    "# You asked for clarification on the meaning of the survived column in the Titanic dataset.\n",
    "# I explained that 0 indicates the passenger did not survive (dead) and 1 indicates the passenger survived (alive).\n",
    "# AttributeError: 'DataFrame' object has no attribute 'decribe':\n",
    "\n",
    "# You encountered an AttributeError due to a typo in your code (df.decribe() instead of df.describe()).\n",
    "# I explained that the error occurred because Python couldn't find the method decribe and provided the correct code df.describe() to resolve the issue.\n",
    "# Common Coding Errors and Fixes:\n",
    "\n",
    "# You summarized a few errors you'd encountered in your code, and I helped troubleshoot them:\n",
    "# Forgetting Parentheses:\n",
    "# Example: pd.read_csv(url (missing closing parenthesis).\n",
    "# Fix: Ensure all parentheses are properly closed, like pd.read_csv(url).\n",
    "# Mistyping Function Names in a Chain:\n",
    "# Example: df.group_by(\"col1\")[\"col2\"].describle().\n",
    "# Fix: Correct function names to df.groupby(\"col1\")[\"col2\"].describe().\n",
    "# Using Incorrect Column Names:\n",
    "# Example: Using Sex instead of sex (column names are case-sensitive).\n",
    "# Fix: Ensure the correct spelling and case for column names, like df.groupby(\"sex\")[\"age\"].describe().\n",
    "# Forgetting Quotes for Column Names:\n",
    "# Example: df.groupby(sex)[\"age\"].describe().\n",
    "# Fix: Column names should be in quotes, as they are strings, like df.groupby(\"sex\")[\"age\"].describe().\n",
    "# Error Handling Strategies:\n",
    "\n",
    "# We discussed whether it's easier to troubleshoot these errors with a ChatBot or through a Google search. I provided explanations on how to interpret and fix various errors like SyntaxError, AttributeError, KeyError, and NameError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "27e48351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot transcript for question 8 https://chatgpt.com/share/66e72b8e-6ef0-8000-9e13-c8f452500662"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
